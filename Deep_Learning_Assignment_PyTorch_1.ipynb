{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388271cb",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment\n",
    "**Instructions:** You have recently watched the first four videos of the 3Blue1Brown deep learning series and the basics of Pytorch videos. This assignment will test your understanding of the concepts presented in those videos. Please answer the questions thoroughly, and write your code in Python using popular deep learning libraries like TensorFlow or PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b702030",
   "metadata": {},
   "source": [
    "## Theoretical Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081400d3",
   "metadata": {},
   "source": [
    "### 1. Neural Network Basics:\n",
    "Explain the following terms in the context of neural networks:\n",
    " 1. Neuron: Inspired by biological neurons, they are the fundamental unit of neuronal network which hold activations, which then be combined with weights and biases for activation in other neuron.\n",
    " 2. Activation Function: A function that return the activation(a number) for neuron based on the weights and biases, that activation ranges from 0 to 1, which we get from sigmoid(or activation) function.\n",
    " 3. Weights and Biases: Weights are defined as the strength of connections betweeen two neurons whereas biases are numbers that is added to the weighted sum for additional adjustments.\n",
    " 4. Feedforward Process: It includes, the data is feed in the network which causes activation in the some neurons, which then collectively causes activation in other neurons of next layer and this process continues, called feedforwarding process.\n",
    " 5. Backpropagation: Tracking of errors which will travel back through network. Computes the gradient of the loss function with respect to each weight in the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f2c97",
   "metadata": {},
   "source": [
    "### 2. Visualizing Neural Networks:\n",
    "Based on the videos, why is visualizing neural networks as \"function layers\" a useful way to understand their operation? Provide an example of how a simple neural network might be visualized this way and what each layer represents.\n",
    "\n",
    "A collective process of input is tedious and time taking, Visualizing the neural networks as function layers helps to breakdown the problem or input into smaller pieces which helps to computer to process smaller inputs effectively in forms of layers.\n",
    "A simple neural network can be visualized in forms of layer each processing a part of input.\n",
    "It can be classified into three basic layers:\n",
    "1. Input layer, as the name suggests takes the inputs as activation on neurons in input layer.\n",
    "2. Hidden layer(s), processes the sections of input after input layer, each hidden layer is depend on the layer before it.\n",
    "3. Output layer, gives the output based on the activation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f62a8c",
   "metadata": {},
   "source": [
    "## Coding Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473c8eb",
   "metadata": {},
   "source": [
    "Run the below cells before running/doing the other to install all the dependancies for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b2a7e7",
   "metadata": {},
   "source": [
    "### 1. Implementing a Single Neuron:\n",
    "- Write a Python function that simulates a single neuron. The function should take a list of inputs, weights, and a bias, and return the output using a sigmoid activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def single_neuron(inputs, weights, bias):\n",
    "    ws = np.dot(inputs, weights) + bias\n",
    "    return sigmoid(ws)\n",
    "    \n",
    "# Example usage\n",
    "inputs = [0.5, 0.6, 0.1]\n",
    "weights = [0.4, 0.3, 0.8]\n",
    "bias = -0.1\n",
    "output = single_neuron(inputs, weights, bias)\n",
    "print('Output:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2461b5",
   "metadata": {},
   "source": [
    "### 2. Building a Simple Neural Network:\n",
    "Using a deep learning library (PyTorch), build a simple neural network with one hidden layer. Use this network to perform binary classification on a small dataset (the XOR dataset). Remember the activation function you are supposed to use is the Sigmoid function, use the one given by pytorch itself, no need to refer to Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e00831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# XOR dataset\n",
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    '''Type you code here'''\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 2)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "model = SimpleNN()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  \n",
    "\n",
    "# Train the model\n",
    "for epoch in range(5000):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()  \n",
    "    loss.backward()        \n",
    "    optimizer.step()      \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/5000], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(X)\n",
    "    predictions = predictions.round()\n",
    "    accuracy = (predictions == y).float().mean()\n",
    "    print(f'Model Accuracy: {accuracy.item() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55d9dd",
   "metadata": {},
   "source": [
    "### 3. Visualizing the Learning Process:\n",
    "Modify the neural network code from Question 2 to record the loss at each epoch. Plot the loss over epochs using Matplotlib to visualize how the network learns over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4219d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Train the model and record the loss\n",
    "for epoch in range(5000):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "\n",
    "# Plot the loss over epochs\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac3842",
   "metadata": {},
   "source": [
    "## Submission Instructions:\n",
    "- Answer the theoretical questions in a separate markdown\n",
    "- Include comments in your code to explain your implementation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
